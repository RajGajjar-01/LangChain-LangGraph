{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "colab-badge",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RajGajjar-01/LangChain-LangGraph/blob/main/Langgraph/13_Human_in_the_loop.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if running in Google Colab\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -U langgraph langchain-huggingface python-dotenv langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "## **Human In The Loop (HITL) in LangGraph**\n",
    "\n",
    "<div class=\"premium-card\">\n",
    "    This notebook demonstrates how to implement <b>Human-in-the-loop</b> patterns using LangGraph's <code>interrupt</code> and <code>Command</code> functionality. HITL is essential for sensitive actions like sending emails or making purchases, ensuring safety and human oversight.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "### **1. Imports and Setup**\n",
    "\n",
    "We import necessary modules for terminal-based interactions and LangGraph state management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "612506f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.types import interrupt\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "### **2. Define Tools with Interrupts**\n",
    "\n",
    "We define a <code>send_email</code> tool that triggers an <b>interrupt</b>. This pauses the graph execution and waits for human approval before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996491ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send an email to a recipient.\"\"\"\n",
    "\n",
    "    approval = interrupt({\n",
    "        \"action\": \"send_email\",\n",
    "        \"to\": to,\n",
    "        \"subject\": subject,\n",
    "        \"body\": body,\n",
    "        \"message\": \"Do you want to send this email\"\n",
    "    })\n",
    "\n",
    "    if approval.get(\"approved\"):\n",
    "        return f\"Email sent to {to} with subject '{subject}'\"\n",
    "    else:\n",
    "        return \"Email cancelled by user\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "### **3. Initialize LLM and Checkpointer**\n",
    "\n",
    "HITL requires a <b>checkpointer</b> to save the state when the graph is interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f60cc46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajgajjar04/Learnings/Langchain_Langgraph/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id='meta-llama/Llama-3.3-70B-Instruct',\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=2048,\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5407753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.redis import RedisSaver\n",
    "\n",
    "checkpointer = None\n",
    "with RedisSaver.from_conn_string(\"redis://localhost:6379\") as _checkpointer:\n",
    "    _checkpointer.setup()\n",
    "    checkpointer = _checkpointer\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[send_email],\n",
    "    system_prompt = \"You are a helpful email assistant. When asked to send emails, use the send_email tool.\",\n",
    "    checkpointer=checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "### **4. Build the Agent**\n",
    "\n",
    "We create the agent using the prebuilt <code>create_agent</code> utility, binding our tools and checkpointer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "### **5. Run with Interrupt**\n",
    "\n",
    "We invoke the agent. It will pause at the <code>send_email</code> tool and return an interrupt state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1f6d860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent paused for approval\n",
      "\n",
      "Interrupt details:\n",
      "  To: alice@example.com\n",
      "  Subject: Meeting Tomorrow\n",
      "  Body: Let's meet at 3pm.\n",
      "  Message: Do you want to send this email\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "config = {\n",
    "    'configurable': {\n",
    "        'thread_id': 'email'\n",
    "    }\n",
    "}\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Send an email to alice@example.com with subject 'Meeting Tomorrow' and body 'Let's meet at 3pm.'\")]\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "if \"__interrupt__\" in result:\n",
    "    print(\"Agent paused for approval\\n\")\n",
    "\n",
    "    interrupt_info = result[\"__interrupt__\"][0]\n",
    "\n",
    "    print(\"Interrupt details:\")\n",
    "    print(f\"  To: {interrupt_info.value['to']}\")\n",
    "    print(f\"  Subject: {interrupt_info.value['subject']}\")\n",
    "    print(f\"  Body: {interrupt_info.value['body']}\")\n",
    "    print(f\"  Message: {interrupt_info.value['message']}\")\n",
    "else:\n",
    "    print(\"Agent completed without interrupt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "### **6. Resume Execution**\n",
    "\n",
    "The human provides approval via <code>Command(resume=...)</code>, allowing the graph to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a6508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Problem\n",
    "# Imagine you're building an agent that can send emails or make purchases. You don't want it to take these actions automatically - you want human approval first!\n",
    "\n",
    "# Human-in-the-loop lets you:\n",
    "\n",
    "# Pause execution for review\n",
    "# Approve, reject, or edit actions\n",
    "# Add safety controls to sensitive operations\n",
    "# How It Works\n",
    "# Agent encounters an interrupt() - execution pauses\n",
    "# System surfaces information to human\n",
    "# Human provides input (approve/reject/edit)\n",
    "# Agent resumes with Command(resume=...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
