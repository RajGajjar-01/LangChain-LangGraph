{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "colab-badge",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RajGajjar-01/LangChain-LangGraph/blob/main/Langgraph/15_Tool_calling.ipynb)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "colab-setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies if running in Google Colab\n",
                "import sys\n",
                "if 'google.colab' in sys.modules:\n",
                "    !pip install -U langgraph langchain-google-genai langchain-huggingface python-dotenv"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7b87109a",
            "metadata": {},
            "source": [
                "## **Tool Calling in LangGraph**\n",
                "\n",
                "<div class=\"premium-card\">\n",
                "    This notebook demonstrates how to implement a basic <b>tool-calling pattern</b> using LangGraph. We create a set of simple mathematical tools and a stateful graph that can route messages between a chatbot and these tools.\n",
                "</div>\n",
                "\n",
                "### **1. Environment Setup and Imports**\n",
                "\n",
                "First, we load environmental variables and import necessary components from LangChain and LangGraph."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a486f332",
            "metadata": {},
            "outputs": [],
            "source": [
                "from dotenv import load_dotenv\n",
                "from typing import Annotated, TypedDict\n",
                "\n",
                "from langchain_google_genai import ChatGoogleGenerativeAI\n",
                "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
                "from langchain_core.tools import tool\n",
                "from langchain_core.messages import HumanMessage\n",
                "\n",
                "from langgraph.graph import StateGraph, START, END\n",
                "from langgraph.graph.message import add_messages\n",
                "from langgraph.prebuilt import ToolNode, tools_condition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0ad0a46d",
            "metadata": {},
            "outputs": [],
            "source": [
                "load_dotenv()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "tool-definition-intro",
            "metadata": {},
            "source": [
                "### **2. Define Tools**\n",
                "\n",
                "We define basic arithmetic operations as tools using the `@tool` decorator. These tools will be called by the LLM when needed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f7d3a874",
            "metadata": {},
            "outputs": [],
            "source": [
                "@tool\n",
                "def add(a:int, b:int) -> int:\n",
                "    \"\"\"Add two numbers\"\"\"\n",
                "    return a + b\n",
                "\n",
                "@tool\n",
                "def multiply(a:int, b:int) -> int:\n",
                "    \"\"\"Multiply two numbers\"\"\"\n",
                "    return a * b\n",
                "\n",
                "@tool\n",
                "def subtract(a:int, b:int) -> int:\n",
                "    \"\"\"Subtract two numbers\"\"\"\n",
                "    return a - b\n",
                "\n",
                "@tool\n",
                "def divide(a:int, b:int) -> int:\n",
                "    \"\"\"divide two numbers\"\"\"\n",
                "    return a // b\n",
                "\n",
                "tools = [add, multiply, subtract, divide]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "state-definition-intro",
            "metadata": {},
            "source": [
                "### **3. Define Graph State**\n",
                "\n",
                "The state of our graph is a simple dictionary containing a list of messages. We use `Annotated` with `add_messages` to ensure that new messages are <b>appended</b> to the existing list."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "96a799a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "class State(TypedDict):\n",
                "    messages : Annotated[list, add_messages]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "node-definition-intro",
            "metadata": {},
            "source": [
                "### **4. Define Nodes (Chatbot)**\n",
                "\n",
                "We define nodes for our graph. The <code>chatbot</code> node uses a model (HuggingFace or Google Gemini) bound with our tools."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "148aab5d",
            "metadata": {},
            "outputs": [],
            "source": [
                "def chatbot2(state: State) -> State:\n",
                "    llm = ChatGoogleGenerativeAI(\n",
                "        model=\"gemini-2.5-flash\",\n",
                "    )\n",
                "\n",
                "    llm_with_tools = llm.bind_tools(tools)\n",
                "    response = llm_with_tools.invoke(state['messages'])\n",
                "    return {\"messages\": [response]}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1ab6ba2f",
            "metadata": {},
            "outputs": [],
            "source": [
                "def chatbot(state: State) -> State:\n",
                "    model = HuggingFaceEndpoint(\n",
                "        repo_id='meta-llama/Llama-3.3-70B-Instruct',\n",
                "        task=\"text-generation\",\n",
                "        max_new_tokens=2048,\n",
                "    )\n",
                "\n",
                "    llm = ChatHuggingFace(llm = model)\n",
                "\n",
                "    llm_with_tools = llm.bind_tools(tools)\n",
                "    response = llm_with_tools.invoke(state['messages'])\n",
                "    return {\"messages\": [response]}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "graph-construction-intro",
            "metadata": {},
            "source": [
                "### **5. Build the Graph**\n",
                "\n",
                "Now we assemble the components into a <code>StateGraph</code>. We add nodes for the chatbot and the tool executor, and define the edges including conditional edges to handle tool calls."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "67ee358f",
            "metadata": {},
            "outputs": [],
            "source": [
                "graph = StateGraph(State)\n",
                "\n",
                "graph.add_node(\"chatbot\", chatbot)\n",
                "\n",
                "tool_node = ToolNode(tools=tools)\n",
                "\n",
                "graph.add_node(\"tools\", tool_node)\n",
                "\n",
                "graph.add_edge(START, \"chatbot\")\n",
                "\n",
                "graph.add_conditional_edges(\"chatbot\", tools_condition)\n",
                "\n",
                "graph.add_edge(\"tools\", \"chatbot\")\n",
                "\n",
                "workflow = graph.compile()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "graph-visualization-intro",
            "metadata": {},
            "source": [
                "### **6. Visualize the Graph**\n",
                "\n",
                "We can visualize the graph structure using Mermaid. This helps in understanding the control flow."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d69e336f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import Image\n",
                "Image(workflow.get_graph().draw_mermaid_png())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "execution-intro",
            "metadata": {},
            "source": [
                "### **7. Run the Workflow**\n",
                "\n",
                "Finally, we run the workflow with a mathematical question to see the <b>tool calling</b> in action."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cfd16199",
            "metadata": {},
            "outputs": [],
            "source": [
                "question = \"Compute (20 + 10) * 4 - 4 / 2. Show steps and use podmas\"\n",
                "\n",
                "result = workflow.invoke(\n",
                "    {\"messages\": [HumanMessage(content=question)]}\n",
                ")\n",
                "\n",
                "print(\"\\n===== FINAL ANSWER =====\\n\")\n",
                "print(result[\"messages\"][-1].content)\n",
                "\n",
                "print(\"\\n===== TRACE (messages) =====\\n\")\n",
                "for m in result[\"messages\"]:\n",
                "    print(type(m).__name__, \"=>\", getattr(m, \"content\", \"\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "langchain-langgraph",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}