{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d211d3bd",
   "metadata": {},
   "source": [
    "Human In The Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0a6508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Problem\n",
    "# Imagine you're building an agent that can send emails or make purchases. You don't want it to take these actions automatically - you want human approval first!\n",
    "\n",
    "# Human-in-the-loop lets you:\n",
    "\n",
    "# Pause execution for review\n",
    "# Approve, reject, or edit actions\n",
    "# Add safety controls to sensitive operations\n",
    "# How It Works\n",
    "# Agent encounters an interrupt() - execution pauses\n",
    "# System surfaces information to human\n",
    "# Human provides input (approve/reject/edit)\n",
    "# Agent resumes with Command(resume=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "612506f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.types import interrupt\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ad4d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f60cc46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajgajjar04/Learnings/Langchain_Langgraph/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id='meta-llama/Llama-3.3-70B-Instruct',\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=2048,\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996491ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send an email to a recipient.\"\"\"\n",
    "\n",
    "    approval = interrupt({\n",
    "        \"action\": \"send_email\",\n",
    "        \"to\": to,\n",
    "        \"subject\": subject,\n",
    "        \"body\": body,\n",
    "        \"message\": \"Do you want to send this email\"\n",
    "    })\n",
    "\n",
    "    if approval.get(\"approved\"):\n",
    "        return f\"Email sent to {to} with subject '{subject}'\"\n",
    "    else:\n",
    "        return \"Email cancelled by user\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5407753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.redis import RedisSaver\n",
    "\n",
    "checkpointer = None\n",
    "with RedisSaver.from_conn_string(\"redis://localhost:6379\") as _checkpointer:\n",
    "    _checkpointer.setup()\n",
    "    checkpointer = _checkpointer\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[send_email],\n",
    "    system_prompt = \"You are a helpful email assistant. When asked to send emails, use the send_email tool.\",\n",
    "    checkpointer=checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f6d860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent paused for approval\n",
      "\n",
      "Interrupt details:\n",
      "  To: alice@example.com\n",
      "  Subject: Meeting Tomorrow\n",
      "  Body: Let's meet at 3pm.\n",
      "  Message: Do you want to send this email\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "config = {\n",
    "    'configurable': {\n",
    "        'thread_id': 'email'\n",
    "    }\n",
    "}\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Send an email to alice@example.com with subject 'Meeting Tomorrow' and body 'Let's meet at 3pm.'\")]\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "if \"__interrupt__\" in result:\n",
    "    print(\"Agent paused for approval\\n\")\n",
    "\n",
    "    interrupt_info = result[\"__interrupt__\"][0]\n",
    "\n",
    "    print(\"Interrupt details:\")\n",
    "    print(f\"  To: {interrupt_info.value['to']}\")\n",
    "    print(f\"  Subject: {interrupt_info.value['subject']}\")\n",
    "    print(f\"  Body: {interrupt_info.value['body']}\")\n",
    "    print(f\"  Message: {interrupt_info.value['message']}\")\n",
    "else:\n",
    "    print(\"Agent completed without interrupt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6547a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final response\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "result = agent.invoke(\n",
    "    Command(resume={'approved': False}),\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"Final response\")\n",
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa8323c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e25dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4677cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
